{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lehuong240823/web-scraping-toolkit/blob/main/FormulaOne.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mPQqX6qbx3qq"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mt5iYO-NkWoS",
        "outputId": "8deff15a-ef92-4c5a-dff8-dfe03633a56b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "https://qrguiding.com/upload/c16a5320fa475530d9583c34fd356ef5/files/1.jpg\n",
            "https://qrguiding.com/upload/c16a5320fa475530d9583c34fd356ef5/files/02.jpg\n",
            "https://qrguiding.com/upload/c16a5320fa475530d9583c34fd356ef5/files/002.jpg\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "import warnings\n",
        "import time\n",
        "from bs4 import BeautifulSoup\n",
        "headers = {\n",
        "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/85.0.4183.121 Safari/537.36'\n",
        "}\n",
        "make_directory(slash.join([r'/content/drive/MyDrive', 'VR']))\n",
        "for attempt in range(1):\n",
        "  warnings.filterwarnings('ignore', message='Unverified HTTPS request')\n",
        "  session = requests.Session()\n",
        "  session.verify = False\n",
        "  try:\n",
        "\n",
        "    index = 0\n",
        "    prefix = ''\n",
        "    for p in range(0, 4):\n",
        "      if p != 0:\n",
        "        prefix = prefix + '0'\n",
        "      for index in range(0, 150):\n",
        "        image_name = prefix + str(index)\n",
        "        img_url = 'https://qrguiding.com/upload/c16a5320fa475530d9583c34fd356ef5/files/' + image_name +'.jpg'\n",
        "        image_filename = slash.join(['/content/drive/MyDrive', 'VR', str(1) + '.jpg'])\n",
        "\n",
        "        img_page = requests.get(img_url, headers=headers, verify=False)\n",
        "        #content = img_page.content.decode('utf-8', 'replace')\n",
        "        #img_soup = bs4.BeautifulSoup(content, 'html.parser')\n",
        "        #img_element = img_soup.find('img')\n",
        "        #if img_soup.title is None :\n",
        "        response = session.get(img_url)\n",
        "        response.raise_for_status()\n",
        "        with open(image_filename, 'wb') as f:\n",
        "          f.write(response.content)\n",
        "        print(img_url)\n",
        "        break\n",
        "  except requests.exceptions.ConnectionError as e:\n",
        "      print(f\"Connection error occurred: {e}\")\n",
        "  except requests.exceptions.RequestException as e:\n",
        "      print(f\"Error downloading image: {e}\")\n",
        "      if attempt < 4:\n",
        "        print(\"Retrying...\")\n",
        "        time.sleep(2)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "115aLx29E6qr",
        "outputId": "f848c68a-755d-44ac-b4fd-7871e31411cc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "import traceback\n",
        "import os\n",
        "from google.colab import files\n",
        "import csv\n",
        "import bs4\n",
        "import requests\n",
        "import shutil\n",
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "drive_path = r'/content/drive/MyDrive/F1'\n",
        "\n",
        "url = r'https://www.formula1.com'\n",
        "path = r'/content'\n",
        "slash  = '/'\n",
        "year_start = 2024\n",
        "year_end = 2025\n",
        "\n",
        "drivers_key = 'drivers'\n",
        "teams_key = 'teams'\n",
        "schedule_key = 'schedule'\n",
        "circuit_key = 'circuits'\n",
        "results_key = 'results'\n",
        "fastest_laps_key = 'fastest-laps'\n",
        "flag_key = 'flags'\n",
        "\n",
        "drivers_path = slash.join([drive_path, drivers_key])\n",
        "position_path = slash.join([drive_path, drivers_key, 'position'])\n",
        "profile_path = slash.join([drive_path, drivers_key, 'profile'])\n",
        "schedule_path = slash.join([drive_path, schedule_key])\n",
        "teams_path = slash.join([drive_path, teams_key])\n",
        "cars_path = slash.join([drive_path, teams_key, 'car'])\n",
        "small_logo_path = slash.join([drive_path, teams_key, 'small logo'])\n",
        "full_logo_path = slash.join([drive_path, teams_key, 'full logo'])\n",
        "circuits_path = slash.join([drive_path, circuit_key])\n",
        "results_path = slash.join([drive_path, results_key])\n",
        "\n",
        "drivers_rel_path = '../img/drivers'\n",
        "teams_rel_path = '../img/teams'\n",
        "\n",
        "pos_rel_path = slash.join([drivers_rel_path, 'position'])\n",
        "profile_rel_path = slash.join([drivers_rel_path, 'profile'])\n",
        "cars_rel_path = slash.join([teams_rel_path, 'car'])\n",
        "small_logo_rel_path = slash.join([teams_rel_path, 'small logo'])\n",
        "full_logo_rel_path = slash.join([teams_rel_path, 'full logo'])\n",
        "\n",
        "\n",
        "drivers_csv = slash.join([drivers_path, drivers_key + '.csv'])\n",
        "teams_csv = slash.join([teams_path, teams_key + '.csv'])\n",
        "schedule_csv = slash.join([schedule_path, schedule_key + '.csv'])\n",
        "sessions_csv = slash.join([schedule_path, 'sessions' + '.csv'])\n",
        "circuits_csv = slash.join([circuits_path, circuit_key + '.csv'])\n",
        "results_csv = slash.join([results_path, results_key + '.csv'])\n",
        "fastest_lap_csv = slash.join([results_path, fastest_laps_key + '.csv'])\n",
        "\n",
        "drivers_field = ['driver_id', 'driver_name', 'team_short_name', 'country', 'podiums', 'points', 'grands_prix_entered', 'world_championships', 'highest_race_finish', 'highest_grid_position', 'date_of_birth', 'place_of_birth', 'position', 'position_png', 'transparent_profile_png', 'profile_avif']\n",
        "teams_field = ['team_id', 'team_short_name', 'full_name', 'base', 'team_chief', 'technical_chief', 'chassis', 'power_unit', 'first_team_entry', 'world_championships', 'highest_race_finish', 'pole_positions', 'fastest_laps', 'car_png', 'small_logo_png', 'full_logo_avif']\n",
        "schedule_field = ['schedule_id', 'year', 'month', 'date', 'round', 'grand_prix', 'grand_prix_title']\n",
        "sessions_field = ['session_id', 'schedule_id', 'month', 'date', 'name']\n",
        "circuits_field = ['circuit_id', 'schedule_id', 'grand_prix', 'name', 'first_grand_prix', 'number_of_laps', 'circuit_length', 'race_distance', 'lap_record', 'carbon_png', 'circuit_avif']\n",
        "results_field = ['results_id', 'type', 'year', 'grand_prix', 'pos', 'no', 'driver', 'car', 'laps', 'time_retired', 'pts']\n",
        "fastest_lap_field = ['fastest_lap_id', 'year', 'grand_prix', 'pos', 'no', 'driver', 'car', 'laps', 'time_of_day', 'time', 'avg_speed']\n",
        "\n",
        "def make_directory(dirname):\n",
        "  if os.path.exists(dirname):\n",
        "    for filename in os.listdir(dirname):\n",
        "          file_path = os.path.join(dirname, filename)\n",
        "          if os.path.isfile(file_path):\n",
        "              os.remove(file_path)\n",
        "          elif os.path.isdir(file_path):\n",
        "              shutil.rmtree(file_path)\n",
        "  else:\n",
        "    os.makedirs(dirname)\n",
        "\n",
        "def download_img(img_url, img_path):\n",
        "  img_data = requests.get(img_url).content\n",
        "  with open(img_path, 'wb') as handler:\n",
        "    handler.write(img_data)\n",
        "\n",
        "def download_folder(dir_to_zip, zip_name):\n",
        "  output_filename = zip_name + '.zip'\n",
        "  delete_dir_after_download = \"No\"\n",
        "  os.system(\"zip -r {} {}\".format(output_filename , dir_to_zip ) )\n",
        "  if delete_dir_after_download == \"Yes\":\n",
        "    os.system(\"rm -r {}\".format(dir_to_zip ) )\n",
        "  files.download(output_filename)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aPIFyfeOj7hg"
      },
      "source": [
        "# **DRIVERS**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "gQcuSaqfEUlO"
      },
      "outputs": [],
      "source": [
        "def download_png():\n",
        "  pos_path = slash.join([position_path, pos_file_name])\n",
        "  png_path = slash.join([profile_path, png_file_name])\n",
        "\n",
        "  download_img(drivers_pos['src'], pos_path)\n",
        "  download_img(drivers_png['src'], png_path)\n",
        "try:\n",
        "  rel_path = '../img/drivers/'\n",
        "  make_directory(drivers_path)\n",
        "  make_directory(profile_path)\n",
        "  make_directory(position_path)\n",
        "  drivers_page = requests.get(slash.join([url, 'en', drivers_key]))\n",
        "  drivers_soup = bs4.BeautifulSoup(drivers_page.content, 'html.parser')\n",
        "\n",
        "  a_elements = drivers_soup.find_all('a', class_=\"group focus-visible:outline-0\")\n",
        "\n",
        "  with open(drivers_csv, mode='w', encoding='utf-8', newline='') as csvfile:\n",
        "    writer = csv.DictWriter(csvfile, fieldnames=drivers_field)\n",
        "    writer.writeheader()\n",
        "    did = 1\n",
        "    for element in a_elements:\n",
        "      driver_url = url + element['href']\n",
        "      driver_page = requests.get(driver_url)\n",
        "      driver_soup = bs4.BeautifulSoup(driver_page.content, 'html.parser')\n",
        "\n",
        "      full_name = element.find('div', class_='flex gap-xxs flex-col f1-driver-name')\n",
        "      driver_name = ' '.join([p.text for p in full_name.find_all('p')])\n",
        "      drivers_pos = full_name.find_next('img', class_=\"f1-c-image f1-utils-square-block text-[6rem]\")\n",
        "      drivers_png = drivers_pos.find_next('img', class_=\"f1-c-image ml-0 mr-0 pr-s max-w-3/4\")\n",
        "      name_element = driver_soup.find('h1', class_='f1-heading tracking-normal text-fs-24px tablet:text-fs-42px leading-tight normal-case font-bold non-italic f1-heading__body font-formulaOne')\n",
        "\n",
        "      if(name_element is not None):\n",
        "        driver_infor = name_element.find_all_next('dd', class_='f1-text font-titillium tracking-normal font-normal non-italic normal-case leading-snug f1-text__body text-fs-17px max-laptop:mb-normal')\n",
        "        driver_avif_img = name_element.find_previous('img', class_='f1-c-image aspect-square laptop:aspect-4/3 desktop:aspect-16/10 w-full overflow-hidden object-cover object-top')\n",
        "        driver_infor = [infor.text for infor in driver_infor]\n",
        "        avif_file_name = (driver_name + '.avif').replace(' ', '-').lower()\n",
        "        avif_path = profile_path + '/' + avif_file_name\n",
        "        if driver_avif_img is not None:\n",
        "          download_img(driver_avif_img['src'], avif_path)\n",
        "      else:\n",
        "        team = element.find('p', class_='f1-heading tracking-normal text-fs-12px leading-tight normal-case font-normal non-italic f1-heading__body font-formulaOne text-greyDark')\n",
        "        driver_infor = [team.text, None, None, None, None, None, None, None, None, None]\n",
        "        avif_file_name = None\n",
        "\n",
        "      pos_file_name = (driver_name + ' position' + '.png').replace(' ', '-').lower()\n",
        "      png_file_name = (driver_name + '.png').replace(' ', '-').lower()\n",
        "\n",
        "      download_png()\n",
        "      if avif_file_name is not None:\n",
        "        avif_file_name = slash.join([profile_rel_path, avif_file_name])\n",
        "\n",
        "      driver_profile = [did, driver_name]  + driver_infor + [drivers_pos['alt'], slash.join([pos_rel_path, pos_file_name]), slash.join([profile_rel_path, png_file_name]), avif_file_name]\n",
        "\n",
        "      writer.writerow(dict(zip(drivers_field, driver_profile)))\n",
        "      did += 1\n",
        "except Exception:\n",
        "  print(traceback.format_exc())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GWRh0R3at8S6"
      },
      "source": [
        "# **TEAMS**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "8kq2mCpxJ9-2"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "  make_directory(teams_path)\n",
        "  make_directory(cars_path)\n",
        "  make_directory(small_logo_path)\n",
        "  make_directory(full_logo_path)\n",
        "  with open(teams_csv, mode='w', encoding='utf-8', newline='') as csvfile:\n",
        "    writer = csv.DictWriter(csvfile, fieldnames=teams_field)\n",
        "    writer.writeheader()\n",
        "    tid = 1\n",
        "    teams_page = requests.get(slash.join([url, 'en', teams_key]))\n",
        "    teams_soup = bs4.BeautifulSoup(teams_page.content, 'html.parser')\n",
        "    a_elements = teams_soup.find_all('a', class_=\"group focus-visible:outline-0\")\n",
        "    for element in a_elements:\n",
        "      team_url = slash.join([url, element['href']])\n",
        "      team_page = requests.get(team_url)\n",
        "      team_soup = bs4.BeautifulSoup(team_page.content, 'html.parser')\n",
        "      team_sname = element.find('span', class_='f1-heading tracking-normal text-fs-20px tablet:text-fs-25px leading-tight normal-case font-bold non-italic f1-heading__body font-formulaOne').text\n",
        "      sname_element = team_soup.find('h1', class_='f1-heading tracking-normal text-fs-24px tablet:text-fs-42px leading-tight normal-case font-normal non-italic f1-heading__body font-formulaOne')\n",
        "      if(sname_element is not None):\n",
        "        full_logo = team_soup.find('img', class_='f1-c-image w-full h-full object-cover')\n",
        "        full_logo_avif =  (team_sname + ' full logo' + '.avif').replace(' ', '-').lower()\n",
        "        download_img(full_logo['src'], slash.join([drive_path, teams_key, 'full logo', full_logo_avif]))\n",
        "        team_infor = team_soup.find_all('dd', class_='f1-text font-titillium tracking-normal font-normal non-italic normal-case leading-snug f1-text__body text-fs-17px max-laptop:mb-normal')\n",
        "      else:\n",
        "        team_infor = []\n",
        "\n",
        "      small_logo = element.find('img', class_=\"f1-c-image h-[2em] ml-auto mr-0\")\n",
        "      small_logo_png = (team_sname + ' small logo' + '.png').replace(' ', '-').lower()\n",
        "      download_img(small_logo['src'], slash.join([drive_path, teams_key, 'small logo', small_logo_png]))\n",
        "\n",
        "      car = element.find_all('img', class_=\"f1-c-image\")[3]\n",
        "      car_png = (team_sname + ' car' + '.png').replace(' ', '-').lower()\n",
        "      download_img(car['src'], slash.join([cars_path, car_png]))\n",
        "\n",
        "      team_profile = [tid, team_sname] + [infor.text for infor in team_infor] + [slash.join([cars_rel_path, car_png]), slash.join([small_logo_rel_path, small_logo_png]), slash.join([full_logo_rel_path, full_logo_avif])]\n",
        "      writer.writerow(dict(zip(teams_field, team_profile)))\n",
        "      tid +=1\n",
        "except Exception:\n",
        "    print(traceback.format_exc())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MmVMj_ZDgIy5"
      },
      "source": [
        "# **UPDATE DRIVERS**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bqOVi61nWn6p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "4f3a9089-bbed-4bea-ed4b-3068319f1023"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-14-bfd36d1a2303>:7: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  drivers_df['team_short_name'] = update_drivers['team_id']\n",
            "<ipython-input-14-bfd36d1a2303>:8: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  drivers_df.rename(columns = {'team_short_name': 'team_id'}, inplace = True)\n"
          ]
        }
      ],
      "source": [
        "drivers_df = pd.read_csv(drivers_csv)\n",
        "teams_df = pd.read_csv(teams_csv)\n",
        "update_drivers = pd.merge(drivers_df, teams_df, on ='team_short_name', how ='left')\n",
        "update_drivers.rename(columns = {'world_championships_x': 'world_championships'}, inplace = True)\n",
        "update_drivers.rename(columns = {'highest_race_finish_x': 'highest_race_finish'}, inplace = True)\n",
        "drivers_df = update_drivers[drivers_df.columns]\n",
        "drivers_df['team_short_name'] = update_drivers['team_id']\n",
        "drivers_df.rename(columns = {'team_short_name': 'team_id'}, inplace = True)\n",
        "drivers_df.to_csv(drivers_csv, index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EmTIaECRuOih"
      },
      "source": [
        "# **SCHEDULE**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "2fXf4WYY-iKQ"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "  make_directory(schedule_path)\n",
        "  with open(schedule_csv,  mode='w', encoding='utf-8', newline='') as csvfile:\n",
        "    writer = csv.DictWriter(csvfile, fieldnames=schedule_field)\n",
        "    writer.writeheader()\n",
        "    rid = 1\n",
        "    for year in range(year_start, year_end):\n",
        "      schedule_page = requests.get(url + '/en/' + 'racing' + '/' + str(year))\n",
        "      schedule_soup = bs4.BeautifulSoup(schedule_page.content, 'html.parser')\n",
        "      round_elements = schedule_soup.find_all('a', class_ = 'outline-offset-4 outline-scienceBlue group outline-0 focus-visible:outline-2')\n",
        "      for round_element in round_elements:\n",
        "        round_url = url + round_element['href']\n",
        "        #round_page = requests.get(round_url)\n",
        "        #round_soup = bs4.BeautifulSoup(round_page.content, 'html.parser')\n",
        "        round_name = round_element.find('p', class_ = 'f1-text font-titillium tracking-normal font-bold non-italic uppercase leading-snug f1-text__micro text-fs-15px text-brand-primary').text\n",
        "        date_elements = round_element.findAll('span', class_ = 'whitespace-nowrap')\n",
        "        for date_element in date_elements:\n",
        "          if date_element.text[0].isnumeric():\n",
        "            round_date = date_element.text\n",
        "          else:\n",
        "            round_month = date_element.text\n",
        "        if round_name == 'FESTIVAL':\n",
        "          round_country = round_element.find('p', class_ = 'f1-heading tracking-normal text-fs-14px leading-tight normal-case font-normal non-italic f1-heading__body font-formulaOne text-brand-white')\n",
        "        else:\n",
        "          round_country = round_element.find('p', class_ = 'f1-heading tracking-normal text-fs-18px leading-tight normal-case font-bold non-italic f1-heading__body font-formulaOne overflow-hidden')\n",
        "        if round_country is not None:\n",
        "          round_country = round_country.text\n",
        "\n",
        "        if round_name == 'FESTIVAL':\n",
        "          round_grand_prix = round_element.find('p', class_ = 'f1-heading tracking-normal text-fs-18px leading-tight normal-case font-bold non-italic f1-heading__body font-formulaOne text-brand-white')\n",
        "        else:\n",
        "          round_grand_prix = round_element.find('p', class_ = 'f1-heading tracking-normal text-fs-12px leading-tight normal-case font-normal non-italic f1-heading__body font-formulaOne')\n",
        "        if round_grand_prix is not None:\n",
        "          round_grand_prix = round_grand_prix.text\n",
        "        round_data = [rid, year, round_month, round_date, round_name, round_country, round_grand_prix]\n",
        "        writer.writerow(dict(zip(schedule_field, round_data)))\n",
        "        rid += 1\n",
        "except Exception:\n",
        "    print(traceback.format_exc())\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-hHDRq1cYNJw"
      },
      "source": [
        "# **SESSIONS**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4EdxWnTZYMld"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "  with open(sessions_csv,  mode='w', encoding='utf-8', newline='') as csvfile:\n",
        "\n",
        "    writer = csv.DictWriter(csvfile, fieldnames=sessions_field)\n",
        "    writer.writeheader()\n",
        "    sid = 1\n",
        "    seid = 1\n",
        "    for year in range(year_start, year_end):\n",
        "      schedule_page = requests.get(url + '/en/' + 'racing' + '/' + str(year))\n",
        "      schedule_soup = bs4.BeautifulSoup(schedule_page.content, 'html.parser')\n",
        "      round_elements = schedule_soup.find_all('a', class_ = 'outline-offset-4 outline-scienceBlue group outline-0 focus-visible:outline-2')\n",
        "      for round_element in round_elements:\n",
        "        round_url = url + round_element['href']\n",
        "        round_page = requests.get(round_url)\n",
        "        round_soup = bs4.BeautifulSoup(round_page.content, 'html.parser')\n",
        "        session_elements = round_soup.find_all('div', class_ = 'relative px-xs py-s tablet:p-normal tablet:pl-0 tablet:pr-normal rounded-md flex flex-wrap tablet:flex-nowrap mt-micro items-center bg-white pr-l')\n",
        "        for session_element in reversed(session_elements):\n",
        "          session_date = session_element.find('p', class_ = 'f1-heading tracking-normal text-fs-18px leading-none normal-case font-normal non-italic f1-heading__body font-formulaOne').text\n",
        "          session_month = session_element.find('div', class_ = 'rounded-xl py-0.5 px-2 mt-1 leading-none inline-block bg-lightGray text-grey-70').text\n",
        "          session_name = session_element.find('span', class_ = 'f1-heading tracking-normal text-fs-18px leading-tight normal-case font-bold non-italic f1-heading__body font-formulaOne block mb-xxs').text\n",
        "          session_data = [seid, sid, session_month, session_date, session_name]\n",
        "          writer.writerow(dict(zip(sessions_field, session_data)))\n",
        "          seid += 1\n",
        "        sid += 1\n",
        "except Exception:\n",
        "    print(traceback.format_exc())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r9gZ9vixuYgK"
      },
      "source": [
        "# **RESULTS**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "PAe-lPhnnPDN"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "  make_directory(results_path)\n",
        "  with open(results_csv,  mode='w', encoding='utf-8', newline='') as csvfile:\n",
        "\n",
        "    writer = csv.DictWriter(csvfile, fieldnames=results_field)\n",
        "    writer.writeheader()\n",
        "\n",
        "    for year in range(year_start, year_end):\n",
        "      results_page = requests.get(url + '/en/' + results_key + '/' + str(year) + '/races')\n",
        "      results_soup = bs4.BeautifulSoup(results_page.content, 'html.parser')\n",
        "      a_elements = results_soup.find_all('a', class_ = 'block')\n",
        "      rid = 1\n",
        "      for a_element in a_elements:\n",
        "        if a_element.text == 'All':\n",
        "          all_grand_prix_elements = a_element\n",
        "          for next_sibling in all_grand_prix_elements.parent.next_siblings:\n",
        "            grand_prix_url = url + next_sibling.findChildren('a', class_ = 'block')[0]['href']\n",
        "            grand_prix_page = requests.get(grand_prix_url)\n",
        "            grand_prix_soup = bs4.BeautifulSoup(grand_prix_page.content, 'html.parser')\n",
        "            race_result_table = grand_prix_soup.find_all('table', class_ = 'f1-table f1-table-with-data w-full')\n",
        "            if len(race_result_table) > 0 and race_result_table[0] is not None:\n",
        "              race_result_table = race_result_table[0]\n",
        "              table_rows = race_result_table.find('tbody').find_all('tr')\n",
        "              for row in table_rows:\n",
        "                result_data = [rid, 'race', year, next_sibling.text]\n",
        "                cells = row.findChildren('td')\n",
        "                for cell in cells:\n",
        "                  if len(cell.findChildren('span'))==3:\n",
        "                    result_data.append(cell.findChildren('span')[0].text + ' ' + cell.findChildren('span')[1].text)\n",
        "                  else:\n",
        "                    result_data.append(cell.text)\n",
        "                writer.writerow(dict(zip(results_field, result_data)))\n",
        "                rid += 1\n",
        "\n",
        "            result_a_element = grand_prix_soup.find_all('a', class_ = 'block')\n",
        "            for a_element in result_a_element:\n",
        "              if a_element.text == 'Sprint':\n",
        "                sprint_url = url + a_element['href']\n",
        "                sprint_page = requests.get(sprint_url)\n",
        "                sprint_soup = bs4.BeautifulSoup(sprint_page.content, 'html.parser')\n",
        "                sprint_table = sprint_soup.find_all('table', class_ = 'f1-table f1-table-with-data w-full')\n",
        "                if len(sprint_table) > 0 and sprint_table[0] is not None:\n",
        "                  sprint_table = sprint_table[0]\n",
        "                  table_rows = sprint_table.find('tbody').find_all('tr')\n",
        "                  for row in table_rows:\n",
        "                    result_data = [rid, 'sprint', year, next_sibling.text]\n",
        "                    cells = row.findChildren('td')\n",
        "                    for cell in cells:\n",
        "                      if len(cell.findChildren('span'))==3:\n",
        "                        result_data.append(cell.findChildren('span')[0].text + ' ' + cell.findChildren('span')[1].text)\n",
        "                      else:\n",
        "                        result_data.append(cell.text)\n",
        "                    writer.writerow(dict(zip(results_field, result_data)))\n",
        "                    rid +=1\n",
        "          break\n",
        "except Exception:\n",
        "    print(traceback.format_exc())\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **UPDATE RESULT**\n",
        "\n"
      ],
      "metadata": {
        "id": "xVIWTb7xWU9I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results_df = pd.read_csv(fastest_lap_csv)\n",
        "schedule_df = pd.read_csv(schedule_csv)\n",
        "update_results = pd.merge(results_df, schedule_df, on =['year', 'grand_prix'], how ='left')\n",
        "results_df = update_results[results_df.columns]\n",
        "results_df['year'] = update_results['schedule_id']\n",
        "results_df.rename(columns = {'year': 'schedule_id'}, inplace = True)\n",
        "results_df = results_df.drop(columns=['grand_prix'])\n",
        "results_df.to_csv(fastest_lap_csv, index=False)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "WTSWqoVUWS71",
        "outputId": "65796d56-151f-43e5-9570-f8a11fdec658"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-16-a18f70647285>:5: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  results_df['year'] = update_results['schedule_id']\n",
            "<ipython-input-16-a18f70647285>:6: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  results_df.rename(columns = {'year': 'schedule_id'}, inplace = True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results_df = pd.read_csv(fastest_lap_csv)\n",
        "driver_df = pd.read_csv(drivers_csv)\n",
        "driver_df.rename(columns = {'driver_name': 'driver'}, inplace = True)\n",
        "update_results = pd.merge(results_df, driver_df, on =['driver'], how ='left')\n",
        "\n",
        "a = str(results_df.loc[0, 'driver'])\n",
        "b = str(driver_df.loc[0, 'driver'])\n",
        "\n",
        "results_df = update_results[results_df.columns]\n",
        "results_df['driver'] = update_results['driver_id']\n",
        "results_df.rename(columns = {'driver': 'driver_id'}, inplace = True)\n",
        "results_df = results_df.drop(columns=['pos'])\n",
        "results_df = results_df.drop(columns=['no'])\n",
        "\n",
        "results_df.to_csv(fastest_lap_csv, index=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FFpTex5rEVt8",
        "outputId": "dc1d6dc9-2431-48a7-bc21-3bb9712e15de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-17-93eea7ddaeb8>:10: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  results_df['driver'] = update_results['driver_id']\n",
            "<ipython-input-17-93eea7ddaeb8>:11: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  results_df.rename(columns = {'driver': 'driver_id'}, inplace = True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hqVZZQC7hNcY"
      },
      "source": [
        "# **FASTEST LAP**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "CrwOHW-mhIuH"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "  with open(fastest_lap_csv,  mode='w', encoding='utf-8', newline='') as csvfile:\n",
        "\n",
        "    writer = csv.DictWriter(csvfile, fieldnames=fastest_lap_field)\n",
        "    writer.writeheader()\n",
        "\n",
        "    for year in range(year_start, year_end):\n",
        "      results_page = requests.get(url + '/en/' + results_key + '/' + str(year) + '/races')\n",
        "      results_soup = bs4.BeautifulSoup(results_page.content, 'html.parser')\n",
        "      a_elements = results_soup.find_all('a', class_ = 'block')\n",
        "      rid = 1\n",
        "      for a_element in a_elements:\n",
        "        if a_element.text == 'All':\n",
        "          all_round_elements = a_element\n",
        "          for next_sibling in all_round_elements.parent.next_siblings:\n",
        "            round_url = url + next_sibling.findChildren('a', class_ = 'block')[0]['href']\n",
        "            round_url = round_url.replace('race-result', 'fastest-laps')\n",
        "            round_page = requests.get(round_url)\n",
        "            round_soup = bs4.BeautifulSoup(round_page.content, 'html.parser')\n",
        "            race_result_table = round_soup.find_all('table', class_ = 'f1-table f1-table-with-data w-full')\n",
        "            if len(race_result_table) > 0 and race_result_table[0] is not None:\n",
        "              race_result_table = race_result_table[0]\n",
        "              table_rows = race_result_table.find('tbody').find_all('tr')\n",
        "              for row in table_rows:\n",
        "                result_data = [rid, year, next_sibling.text]\n",
        "                cells = row.findChildren('td')\n",
        "                for cell in cells:\n",
        "                  if len(cell.findChildren('span'))==3:\n",
        "                    result_data.append(cell.findChildren('span')[0].text + ' ' + cell.findChildren('span')[1].text)\n",
        "                  else:\n",
        "                    result_data.append(cell.text)\n",
        "                writer.writerow(dict(zip(fastest_lap_field, result_data)))\n",
        "                rid += 1\n",
        "          break\n",
        "except Exception:\n",
        "    print(traceback.format_exc())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **UPDATE FLAPS**"
      ],
      "metadata": {
        "id": "r9HHnfuoizYu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fastest_laps_df = pd.read_csv(fastest_lap_csv)\n",
        "schedule_df = pd.read_csv(schedule_csv)\n",
        "update_results = pd.merge(fastest_laps_df, schedule_df, on =['year', 'grand_prix'], how ='left')\n",
        "fastest_laps_df = update_results[fastest_laps_df.columns]\n",
        "fastest_laps_df['year'] = update_results['schedule_id']\n",
        "fastest_laps_df.rename(columns = {'year': 'schedule_id'}, inplace = True)\n",
        "fastest_laps_df = fastest_laps_df.drop(columns=['grand_prix'])\n",
        "fastest_laps_df.to_csv(fastest_lap_csv, index=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "nPyzmnQojANU",
        "outputId": "16387718-5399-4274-c63a-615ae7fe559c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/drive/MyDrive/F1/results/fastest-laps.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-55-8abbc8476b06>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfastest_laps_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfastest_lap_csv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mschedule_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mschedule_csv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mupdate_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfastest_laps_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mschedule_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mon\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'year'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'grand_prix'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhow\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;34m'left'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mfastest_laps_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mupdate_results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfastest_laps_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mfastest_laps_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'year'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mupdate_results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'schedule_id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/F1/results/fastest-laps.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FUUPkqb4YVfz"
      },
      "source": [
        "# **CIRCUITS**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import chardet\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "# Fetch the page\n",
        "url = url + '/en/' + 'racing' + '/' + str(2024)\n",
        "response = requests.get(url)\n",
        "\n",
        "# Detect encoding\n",
        "result = chardet.detect(response.content)\n",
        "encoding = result['encoding']\n",
        "\n",
        "# Set the encoding based on detection\n",
        "response.encoding = encoding\n",
        "print(response.encoding)\n",
        "# Parse the content with Beautiful Soup\n",
        "soup = BeautifulSoup(response.text, 'html.parser')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9DEiMY1sPg3f",
        "outputId": "4b341e64-f495-4939-fd10-b4f600b71724"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "utf-8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "5s5k_iPtYWGJ"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "  rel_path = '../img/circuits/'\n",
        "  make_directory(circuits_path)\n",
        "  with open(circuits_csv,  mode='w', encoding='utf-8', newline='') as csvfile:\n",
        "    writer = csv.DictWriter(csvfile, fieldnames=circuits_field)\n",
        "    writer.writeheader()\n",
        "    sid = 1\n",
        "    cid = 1\n",
        "    for year in range(year_start, year_end):\n",
        "      schedule_page = requests.get(url + '/en/' + 'racing' + '/' + str(year))\n",
        "      schedule_soup = bs4.BeautifulSoup(schedule_page.content, 'html.parser')\n",
        "      round_elements = schedule_soup.find_all('a', class_ = 'outline-offset-4 outline-scienceBlue group outline-0 focus-visible:outline-2')\n",
        "      for round_element in round_elements:\n",
        "        round_url = url + round_element['href']\n",
        "        round_page = requests.get(round_url)\n",
        "        round_soup = bs4.BeautifulSoup(round_page.content, 'html.parser')\n",
        "        round_name = round_element.find('p', class_ = 'f1-text font-titillium tracking-normal font-bold non-italic uppercase leading-snug f1-text__micro text-fs-15px text-brand-primary').text\n",
        "        if round_name == 'FESTIVAL':\n",
        "          round_country = round_element.find('p', class_ = 'f1-heading tracking-normal text-fs-14px leading-tight normal-case font-normal non-italic f1-heading__body font-formulaOne text-brand-white')\n",
        "        else:\n",
        "          round_country = round_element.find('p', class_ = 'f1-heading tracking-normal text-fs-18px leading-tight normal-case font-bold non-italic f1-heading__body font-formulaOne overflow-hidden')\n",
        "        if round_country is not None:\n",
        "          round_country = round_country.text\n",
        "        circuit_country = round_country\n",
        "\n",
        "        circuit_data = [cid, sid, circuit_country]\n",
        "        circuit_carbon_img = round_soup.find('img', class_ = 'desktop:w-[70%] laptop:w-2/5 w-60 mx-auto')\n",
        "        if circuit_carbon_img is not None:\n",
        "          carbon_name = (circuit_country + ' carbon' + '.png').replace(' ', '-').lower()\n",
        "          #carbon_path = slash.join([circuits_path, carbon_name])\n",
        "          download_img(circuit_carbon_img['src'], slash.join([circuits_path, carbon_name]))\n",
        "\n",
        "        circuit_elements = round_soup.find_all('a', class_ = 'grid grid-flow-col auto-cols-max rounded-5 cursor-pointer items-center transition-colors duration-200 font-titillium font-[600] w-full min-w-max laptop:w-auto laptop:text-center laptop:auto-cols-auto focus-visible:outline focus-visible:outline-offset-2 focus-visible:outline-[3px] focus-visible:outline-carbonBlack disabled:pointer-events-none disabled:opacity-75 disabled:cursor-default text-12 px-[15px] gap-[8px] h-[39px] !rounded-none !border-b !border-b-gray20 !auto-cols-auto !text-left !min-w-fit !flex !text-15 !h-auto py-2.5 pl-0 focus-visible:!outline-2 hover:!border-b-primary hover:!text-primary focus:!border-b-primary focus:!text-primary !text-15')\n",
        "        for circuit_element in circuit_elements:\n",
        "          if circuit_element is not None and circuit_element['data-navigation-element'] == 'circuitStats':\n",
        "            circuit_page = requests.get(circuit_element['href'])\n",
        "            circuit_soup = bs4.BeautifulSoup(circuit_page.content, 'html.parser')\n",
        "            circuit_img = circuit_soup.find('img', class_ = 'f1-c-image w-full h-auto object-cover')\n",
        "            if circuit_img is not None:\n",
        "              circuit_img_name = (circuit_data[2] + ' circuit' + '.avif').replace(' ', '-').lower()\n",
        "              download_img(circuit_img['src'], slash.join([circuits_path, circuit_img_name]))\n",
        "            circuit_name = circuit_soup.find('h2', class_ = 'f1-heading tracking-normal text-fs-20px tablet:text-fs-25px leading-none normal-case font-bold non-italic f1-heading__body font-formulaOne block laptop:hidden')\n",
        "            if circuit_name is not None:\n",
        "              circuit_name = circuit_name.text\n",
        "              circuit_infor = circuit_soup.find_all('h2', class_ = 'f1-heading tracking-normal text-fs-22px tablet:text-fs-32px leading-tight normal-case font-bold non-italic f1-heading__body font-formulaOne')\n",
        "\n",
        "              circuit_data = circuit_data + [circuit_name] + [infor.text for infor in circuit_infor] + [rel_path + carbon_name, rel_path + circuit_img_name]\n",
        "              #print(circuit_data)\n",
        "        writer.writerow(dict(zip(circuits_field, circuit_data)))\n",
        "        cid += 1\n",
        "        sid += 1\n",
        "except Exception:\n",
        "    print(traceback.format_exc())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KECqXYWzwkHz"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "circuits_df = pd.read_csv(circuits_csv)\n",
        "circuits_df.fillna('', inplace=True)\n",
        "circuits_df.to_csv(circuits_csv, index=False)"
      ],
      "metadata": {
        "id": "4I4moDhDZ4Wz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n6JrkZ1Ttz_k",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "circuits_df = pd.read_csv(circuits_csv)\n",
        "schedule_df = pd.read_csv(schedule_csv)\n",
        "update_schedule = pd.merge(schedule_df, circuits_df, on ='schedule_id', how ='left')\n",
        "schedule_df.insert(loc=schedule_df.columns.get_loc('schedule_id') + 1, column='circuit_id', value=circuits_df['circuit_id'])\n",
        "schedule_df = schedule_df.drop(columns=['grand_prix'])\n",
        "schedule_df.to_csv(schedule_csv, index=False)\n",
        "circuits_df = circuits_df.drop(columns=['schedule_id'])\n",
        "circuits_df.to_csv(circuits_csv, index=False)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(circuits_csv)\n",
        "print(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MFwz4TaNXvAk",
        "outputId": "a52b17ef-73cc-43c8-c0f6-f897494cba9c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    circuit_id      grand_prix                                          name  \\\n",
            "0            1          Sakhir                 Bahrain International Circuit   \n",
            "1            2         Bahrain                 Bahrain International Circuit   \n",
            "2            3    Saudi Arabia                       Jeddah Corniche Circuit   \n",
            "3            4       Australia                Albert Park Grand Prix Circuit   \n",
            "4            5           Japan                                Suzuka Circuit   \n",
            "5            6           China                Shanghai International Circuit   \n",
            "6            7           Miami                 Miami International Autodrome   \n",
            "7            8  Emilia-Romagna  Autodromo Internazionale Enzo e Dino Ferrari   \n",
            "8            9          Monaco                             Circuit de Monaco   \n",
            "9           10          Canada                     Circuit Gilles-Villeneuve   \n",
            "10          11           Spain                Circuit de Barcelona-Catalunya   \n",
            "11          12         Austria                                 Red Bull Ring   \n",
            "12          13   Great Britain                           Silverstone Circuit   \n",
            "13          14         Hungary                                   Hungaroring   \n",
            "14          15         Belgium                  Circuit de Spa-Francorchamps   \n",
            "15          16     Netherlands                             Circuit Zandvoort   \n",
            "16          17           Italy                     Autodromo Nazionale Monza   \n",
            "17          18      Azerbaijan                             Baku City Circuit   \n",
            "18          19       Singapore                     Marina Bay Street Circuit   \n",
            "19          20   United States                       Circuit of The Americas   \n",
            "20          21          Mexico                  Autdromo Hermanos Rodrguez   \n",
            "21          22          Brazil                    Autdromo Jos Carlos Pace   \n",
            "22          23       Las Vegas                       Las Vegas Strip Circuit   \n",
            "23          24           Qatar                  Lusail International Circuit   \n",
            "24          25       Abu Dhabi                            Yas Marina Circuit   \n",
            "\n",
            "    first_grand_prix number_of_laps                   circuit_length  \\\n",
            "0               2004       5.412 km  1:31.447Pedro de la Rosa (2005)   \n",
            "1               2004            57                          5.412 km   \n",
            "2               2021            50                          6.174 km   \n",
            "3               1996            58                          5.278 km   \n",
            "4               1987            53                          5.807 km   \n",
            "5               2004            56                          5.451 km   \n",
            "6               2022            57                          5.412 km   \n",
            "7               1980            63                          4.909 km   \n",
            "8               1950            78                          3.337 km   \n",
            "9               1978            70                          4.361 km   \n",
            "10              1991            66                          4.657 km   \n",
            "11              1970            71                          4.318 km   \n",
            "12              1950            52                          5.891 km   \n",
            "13              1986            70                          4.381 km   \n",
            "14              1950            44                          7.004 km   \n",
            "15              1952            72                          4.259 km   \n",
            "16              1950            53                          5.793 km   \n",
            "17              2016            51                          6.003 km   \n",
            "18              2008            62                           4.94 km   \n",
            "19              2012            56                          5.513 km   \n",
            "20              1963            71                          4.304 km   \n",
            "21              1973            71                          4.309 km   \n",
            "22              2023            50                          6.201 km   \n",
            "23              2021            57                          5.419 km   \n",
            "24              2009            58                          5.281 km   \n",
            "\n",
            "                        race_distance                           lap_record  \\\n",
            "0   ../img/circuits/sakhir-carbon.png  ../img/circuits/sakhir-circuit.avif   \n",
            "1                          308.238 km      1:31.447Pedro de la Rosa (2005)   \n",
            "2                           308.45 km        1:30.734Lewis Hamilton (2021)   \n",
            "3                          306.124 km       1:19.813Charles Leclerc (2024)   \n",
            "4                          307.471 km        1:30.983Lewis Hamilton (2019)   \n",
            "5                          305.066 km    1:32.238Michael Schumacher (2004)   \n",
            "6                          308.326 km        1:29.708Max Verstappen (2023)   \n",
            "7                          309.049 km        1:15.484Lewis Hamilton (2020)   \n",
            "8                          260.286 km        1:12.909Lewis Hamilton (2021)   \n",
            "9                           305.27 km       1:13.078Valtteri Bottas (2019)   \n",
            "10                         307.236 km        1:16.330Max Verstappen (2023)   \n",
            "11                         306.452 km          1:05.619Carlos Sainz (2020)   \n",
            "12                         306.198 km        1:27.097Max Verstappen (2020)   \n",
            "13                          306.63 km        1:16.627Lewis Hamilton (2020)   \n",
            "14                         308.052 km          1:44.701Sergio Perez (2024)   \n",
            "15                         306.587 km        1:11.097Lewis Hamilton (2021)   \n",
            "16                          306.72 km    1:21.046Rubens Barrichello (2004)   \n",
            "17                         306.049 km       1:43.009Charles Leclerc (2019)   \n",
            "18                         306.143 km      1:34.486Daniel Ricciardo (2024)   \n",
            "19                         308.405 km       1:36.169Charles Leclerc (2019)   \n",
            "20                         305.354 km       1:17.774Valtteri Bottas (2021)   \n",
            "21                         305.879 km       1:10.540Valtteri Bottas (2018)   \n",
            "22                         309.958 km         1:35.490Oscar Piastri (2023)   \n",
            "23                         308.611 km        1:24.319Max Verstappen (2023)   \n",
            "24                         306.183 km        1:26.103Max Verstappen (2021)   \n",
            "\n",
            "                                   carbon_png  \\\n",
            "0                                         NaN   \n",
            "1          ../img/circuits/bahrain-carbon.png   \n",
            "2     ../img/circuits/saudi-arabia-carbon.png   \n",
            "3        ../img/circuits/australia-carbon.png   \n",
            "4            ../img/circuits/japan-carbon.png   \n",
            "5            ../img/circuits/china-carbon.png   \n",
            "6            ../img/circuits/miami-carbon.png   \n",
            "7   ../img/circuits/emilia-romagna-carbon.png   \n",
            "8           ../img/circuits/monaco-carbon.png   \n",
            "9           ../img/circuits/canada-carbon.png   \n",
            "10           ../img/circuits/spain-carbon.png   \n",
            "11         ../img/circuits/austria-carbon.png   \n",
            "12   ../img/circuits/great-britain-carbon.png   \n",
            "13         ../img/circuits/hungary-carbon.png   \n",
            "14         ../img/circuits/belgium-carbon.png   \n",
            "15     ../img/circuits/netherlands-carbon.png   \n",
            "16           ../img/circuits/italy-carbon.png   \n",
            "17      ../img/circuits/azerbaijan-carbon.png   \n",
            "18       ../img/circuits/singapore-carbon.png   \n",
            "19   ../img/circuits/united-states-carbon.png   \n",
            "20          ../img/circuits/mexico-carbon.png   \n",
            "21          ../img/circuits/brazil-carbon.png   \n",
            "22       ../img/circuits/las-vegas-carbon.png   \n",
            "23           ../img/circuits/qatar-carbon.png   \n",
            "24       ../img/circuits/abu-dhabi-carbon.png   \n",
            "\n",
            "                                   circuit_avif  \n",
            "0                                           NaN  \n",
            "1          ../img/circuits/bahrain-circuit.avif  \n",
            "2     ../img/circuits/saudi-arabia-circuit.avif  \n",
            "3        ../img/circuits/australia-circuit.avif  \n",
            "4            ../img/circuits/japan-circuit.avif  \n",
            "5            ../img/circuits/china-circuit.avif  \n",
            "6            ../img/circuits/miami-circuit.avif  \n",
            "7   ../img/circuits/emilia-romagna-circuit.avif  \n",
            "8           ../img/circuits/monaco-circuit.avif  \n",
            "9           ../img/circuits/canada-circuit.avif  \n",
            "10           ../img/circuits/spain-circuit.avif  \n",
            "11         ../img/circuits/austria-circuit.avif  \n",
            "12   ../img/circuits/great-britain-circuit.avif  \n",
            "13         ../img/circuits/hungary-circuit.avif  \n",
            "14         ../img/circuits/belgium-circuit.avif  \n",
            "15     ../img/circuits/netherlands-circuit.avif  \n",
            "16           ../img/circuits/italy-circuit.avif  \n",
            "17      ../img/circuits/azerbaijan-circuit.avif  \n",
            "18       ../img/circuits/singapore-circuit.avif  \n",
            "19   ../img/circuits/united-states-circuit.avif  \n",
            "20          ../img/circuits/mexico-circuit.avif  \n",
            "21          ../img/circuits/brazil-circuit.avif  \n",
            "22       ../img/circuits/las-vegas-circuit.avif  \n",
            "23           ../img/circuits/qatar-circuit.avif  \n",
            "24       ../img/circuits/abu-dhabi-circuit.avif  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-S9T1bwJk1gc"
      },
      "source": [
        "# **FLAGS**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "B8_7BlTa7LD5"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "  make_directory(drive_path + flag_key)\n",
        "  make_directory(drive_path + flag_key + drivers_key)\n",
        "  make_directory(drive_path + flag_key + schedule_key)\n",
        "\n",
        "  drivers_page = requests.get(url + '/en/' + drivers_key)\n",
        "  drivers_soup = bs4.BeautifulSoup(drivers_page.content, 'html.parser')\n",
        "  driver_flags= drivers_soup.find_all('img', class_=\"f1-c-image h-[2em] ml-auto mr-0 border border-greyDark rounded-xxs\")\n",
        "  for flag in driver_flags:\n",
        "    flag_name = flag['alt']\n",
        "    flag_url = flag['src']\n",
        "    flag_path = drive_path + flag_key + '/' + drivers_key + '/' + flag_name + '.jpg'\n",
        "    download_img(flag_url, flag_path)\n",
        "\n",
        "\n",
        "  for year in range(year_start, year_end):\n",
        "    schedule_page = requests.get(url + '/en/' + 'racing' + '/' + str(year))\n",
        "    schedule_soup = bs4.BeautifulSoup(schedule_page.content, 'html.parser')\n",
        "    wrappers_div = schedule_soup.find_all(class_='f1-inner-wrapper flex flex-col gap-xs overflow-clip h-full overflow-visible outline-brand-primary')\n",
        "    for wrapper in wrappers_div:\n",
        "      schedule_flag = wrapper.find('img', class_=\"f1-c-image h-[1.625rem] ml-auto mr-0 rounded-xxs border border-greyDark\")\n",
        "      flag_name = wrapper.find('p', class_=\"f1-heading tracking-normal text-fs-18px leading-tight normal-case font-bold non-italic f1-heading__body font-formulaOne overflow-hidden\")\n",
        "      if schedule_flag is None:\n",
        "        schedule_flag = wrapper.find('img', class_=\"f1-c-image h-[1.125rem] ml-auto mr-0 rounded-xxs border border-greyDark\")\n",
        "      if schedule_flag is not None and flag_name is not None:\n",
        "        flag_name = flag_name.text\n",
        "        flag_url = schedule_flag['src']\n",
        "        flag_path = drive_path + flag_key + '/' + schedule_key + '/' + flag_name + '.png'\n",
        "        download_img(flag_url, flag_path)\n",
        "\n",
        "except Exception:\n",
        "    print(traceback.format_exc())\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "aPIFyfeOj7hg",
        "GWRh0R3at8S6",
        "MmVMj_ZDgIy5",
        "EmTIaECRuOih",
        "-hHDRq1cYNJw",
        "hqVZZQC7hNcY",
        "-S9T1bwJk1gc"
      ],
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}